{
    "6b5b8b214ebb6cc8ec3f7dd521bc072e973b5378": {
        "authored_data": "2013 Jul 20 06:27",
        "commit.message": "improve memory usage of metadata\n",
        "commit.author.name": "julien",
        "pcid": "f46bdafe245db2f6f010ff3ff56858ada695d0f3",
        "changes": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": {
                "old": {
                    "('parquet.format.converter#ParquetMetadataConverter', 'addRowGroup(ParquetMetadata,List,BlockMetaData)')": [
                        137
                    ],
                    "('parquet.format.converter#ParquetMetadataConverter', 'toFormatEncodings(List)')": [
                        154,
                        155
                    ],
                    "('parquet.format.converter#ParquetMetadataConverter', None)": [
                        164,
                        165,
                        166,
                        173,
                        174,
                        175,
                        176,
                        177,
                        178,
                        179,
                        180,
                        181,
                        182,
                        196,
                        197,
                        328,
                        329,
                        330,
                        331,
                        332,
                        333,
                        334,
                        335,
                        336,
                        337,
                        338,
                        339,
                        340,
                        341,
                        342,
                        343,
                        344,
                        345,
                        346,
                        347,
                        348,
                        349,
                        350,
                        351,
                        352
                    ],
                    "('parquet.format.converter#ParquetMetadataConverter', 'fromFormatEncodings(List)')": [
                        198,
                        199,
                        203,
                        205
                    ],
                    "('parquet.format.converter#ParquetMetadataConverter', 'fromParquetMetadata(FileMetaData)')": [
                        297,
                        298,
                        300,
                        302,
                        303,
                        304,
                        305,
                        306,
                        307
                    ],
                    "('parquet.format.converter#ParquetMetadataConverter', 'getPath(parquet)')": [
                        353,
                        355,
                        356,
                        357,
                        358,
                        359,
                        360,
                        361,
                        362,
                        363,
                        364
                    ]
                },
                "new": {
                    "(None, None)": [
                        28,
                        50
                    ],
                    "('parquet.format.converter#ParquetMetadataConverter', 'addRowGroup(ParquetMetadata,List,BlockMetaData)')": [
                        139
                    ],
                    "('parquet.format.converter#ParquetMetadataConverter', 'toFormatEncodings(Set)')": [
                        156,
                        157
                    ],
                    "('parquet.format.converter#ParquetMetadataConverter', None)": [
                        166,
                        167,
                        168,
                        175,
                        176,
                        190,
                        191
                    ],
                    "('parquet.format.converter#ParquetMetadataConverter', 'fromFormatEncodings(List)')": [
                        192,
                        193,
                        197,
                        199
                    ],
                    "('parquet.format.converter#ParquetMetadataConverter', 'fromParquetMetadata(FileMetaData)')": [
                        291,
                        292,
                        294,
                        296,
                        297,
                        298,
                        299,
                        300,
                        301
                    ],
                    "('parquet.format.converter#ParquetMetadataConverter', 'getPath(parquet)')": [
                        322,
                        324
                    ]
                }
            },
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": {
                "old": {
                    "('parquet.hadoop#ColumnChunkPageReadStore', 'getPageReader(ColumnDescriptor)')": [
                        121
                    ]
                },
                "new": {
                    "('parquet.hadoop#ColumnChunkPageReadStore', 'getPageReader(ColumnDescriptor)')": [
                        121
                    ]
                }
            },
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": {
                "old": {
                    "('parquet.hadoop#ParquetFileReader', None)": [
                        277,
                        293
                    ],
                    "('parquet.hadoop#ParquetFileReader', 'readNextRowGroup')": [
                        313
                    ],
                    "('parquet.hadoop#ParquetFileReader', 'readColumnChunkPages(ColumnDescriptor,ColumnChunkMetaData,List,List)')": [
                        344
                    ]
                },
                "new": {
                    "(None, None)": [
                        59
                    ],
                    "('parquet.hadoop#ParquetFileReader', None)": [
                        278,
                        294
                    ],
                    "('parquet.hadoop#ParquetFileReader', 'readNextRowGroup')": [
                        314
                    ],
                    "('parquet.hadoop#ParquetFileReader', 'readColumnChunkPages(ColumnDescriptor,ColumnChunkMetaData,List,List)')": [
                        345
                    ]
                }
            },
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": {
                "old": {
                    "(None, None)": [
                        19
                    ],
                    "('parquet.hadoop#ParquetFileWriter', 'startColumn(ColumnDescriptor,long,CompressionCodecName)')": [
                        173,
                        174,
                        175
                    ],
                    "('parquet.hadoop#ParquetFileWriter', 'writeDictionaryPage(DictionaryPage)')": [
                        187
                    ],
                    "('parquet.hadoop#ParquetFileWriter', 'endColumn')": [
                        264,
                        265,
                        266,
                        267
                    ]
                },
                "new": {
                    "(None, None)": [
                        45,
                        51
                    ],
                    "('parquet.hadoop#ParquetFileWriter', None)": [
                        77,
                        78,
                        79,
                        80,
                        81,
                        82,
                        83
                    ],
                    "('parquet.hadoop#ParquetFileWriter', 'startColumn(ColumnDescriptor,long,CompressionCodecName)')": [
                        181,
                        182,
                        183,
                        184,
                        185
                    ],
                    "('parquet.hadoop#ParquetFileWriter', 'writeDictionaryPage(DictionaryPage)')": [
                        197
                    ],
                    "('parquet.hadoop#ParquetFileWriter', 'endColumn')": [
                        274,
                        275,
                        276,
                        277,
                        278,
                        279,
                        280,
                        281,
                        282,
                        283
                    ]
                }
            },
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": {
                "old": {
                    "('parquet.hadoop#ParquetInputFormat', 'generateSplits(List,BlockLocation,FileStatus,FileMetaData,Class,String,Map)')": [
                        200
                    ]
                },
                "new": {
                    "('parquet.hadoop#ParquetInputFormat', 'generateSplits(List,BlockLocation,FileStatus,FileMetaData,Class,String,Map)')": [
                        200
                    ]
                }
            },
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": {
                "old": {
                    "('parquet.hadoop#ParquetInputSplit', 'readColumn(DataInput)')": [
                        251,
                        255,
                        256,
                        257,
                        258,
                        259,
                        260
                    ],
                    "('parquet.hadoop#ParquetInputSplit', 'writeColumn(DataOutput,ColumnChunkMetaData)')": [
                        267
                    ]
                },
                "new": {
                    "(None, None)": [
                        26,
                        30,
                        39
                    ],
                    "('parquet.hadoop#ParquetInputSplit', 'readColumn(DataInput)')": [
                        254,
                        258,
                        259,
                        260
                    ],
                    "('parquet.hadoop#ParquetInputSplit', 'writeColumn(DataOutput,ColumnChunkMetaData)')": [
                        267
                    ]
                }
            },
            "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": {
                "old": {
                    "('parquet.hadoop#PrintFooter', 'add(ParquetMetadata)')": [
                        168
                    ],
                    "('parquet.hadoop#PrintFooter', None)": [
                        239
                    ],
                    "('parquet.hadoop#PrintFooter', 'add(ColumnDescriptor,long,long,long,List)')": [
                        258
                    ]
                },
                "new": {
                    "(None, None)": [
                        23
                    ],
                    "('parquet.hadoop#PrintFooter', 'add(ParquetMetadata)')": [
                        169
                    ],
                    "('parquet.hadoop#PrintFooter', None)": [
                        240
                    ],
                    "('parquet.hadoop#PrintFooter', 'add(ColumnDescriptor,long,long,long,Collection)')": [
                        259
                    ]
                }
            },
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": {
                "old": {
                    "(None, None)": [
                        18,
                        19,
                        23,
                        28
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', None)": [
                        30,
                        31,
                        32,
                        33,
                        34,
                        35,
                        36,
                        37,
                        38,
                        39,
                        40,
                        41,
                        42,
                        43,
                        44,
                        45,
                        51,
                        52,
                        53,
                        54,
                        55,
                        56,
                        57,
                        58,
                        61,
                        62,
                        63,
                        64,
                        65,
                        66,
                        69,
                        70,
                        71,
                        72,
                        73,
                        76,
                        77,
                        78,
                        79,
                        80,
                        83,
                        84,
                        85,
                        86,
                        87,
                        107,
                        108,
                        111,
                        112,
                        113,
                        128,
                        129,
                        132,
                        133,
                        134,
                        141,
                        142,
                        143,
                        146,
                        147,
                        148,
                        149,
                        150,
                        153,
                        154,
                        155
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'getCodec')": [
                        59,
                        60
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'getPath')": [
                        67,
                        68
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'getType')": [
                        74,
                        75
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'setFirstDataPageOffset(long)')": [
                        81,
                        82
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'setDictionaryPageOffset(long)')": [
                        88,
                        89
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'setValueCount(long)')": [
                        109,
                        110
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'setTotalUncompressedSize(long)')": [
                        130,
                        131
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'setTotalSize(long)')": [
                        144
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'getEncodings')": [
                        151,
                        152
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'toString')": [
                        156,
                        157
                    ]
                },
                "new": {
                    "(None, None)": [
                        18,
                        121,
                        122,
                        192
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', None)": [
                        27,
                        28,
                        56,
                        57,
                        58,
                        59,
                        60,
                        61,
                        62,
                        63,
                        64,
                        65,
                        68,
                        69,
                        70,
                        71,
                        72,
                        73,
                        76,
                        77,
                        78,
                        79,
                        80,
                        83,
                        84,
                        85,
                        86,
                        87,
                        88,
                        90,
                        91,
                        92,
                        93,
                        95,
                        96,
                        97,
                        98,
                        100,
                        101,
                        102,
                        103,
                        105,
                        106,
                        107,
                        108,
                        110,
                        111,
                        112,
                        113,
                        116,
                        117,
                        118
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'get(ColumnPath,PrimitiveTypeName,CompressionCodecName,Set,long,long,long,long,long)')": [
                        29,
                        30,
                        31,
                        32,
                        33,
                        34,
                        35,
                        36,
                        37,
                        38,
                        39,
                        40,
                        41,
                        42,
                        43,
                        44,
                        45,
                        46,
                        47,
                        48,
                        49,
                        50,
                        51,
                        52,
                        53,
                        54,
                        55
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'getCodec')": [
                        66,
                        67
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'getPath')": [
                        74,
                        75
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'getType')": [
                        81,
                        82
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'getFirstDataPageOffset')": [
                        89
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'getDictionaryPageOffset')": [
                        94
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'getValueCount')": [
                        99
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'getTotalUncompressedSize')": [
                        104
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'getTotalSize')": [
                        109
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'getEncodings')": [
                        114,
                        115
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', 'toString')": [
                        119,
                        120
                    ],
                    "('parquet.hadoop.metadata#IntColumnChunkMetaData', None)": [
                        123,
                        124,
                        125,
                        126,
                        127,
                        128,
                        129,
                        134,
                        136,
                        137,
                        138,
                        139,
                        140,
                        141,
                        142,
                        143,
                        144,
                        145,
                        146,
                        147,
                        148,
                        149,
                        150,
                        151,
                        152,
                        153,
                        154
                    ],
                    "('parquet.hadoop.metadata#LongColumnChunkMetaData', None)": [
                        193,
                        194,
                        195,
                        196,
                        197,
                        198,
                        199,
                        200,
                        201,
                        202,
                        203,
                        204,
                        205,
                        206,
                        207,
                        208,
                        209,
                        210,
                        211,
                        212,
                        213,
                        214,
                        215,
                        216,
                        217,
                        218,
                        219,
                        220,
                        221,
                        222,
                        224,
                        225,
                        226,
                        227,
                        228,
                        229,
                        232,
                        233,
                        234,
                        235,
                        236,
                        239,
                        240,
                        241,
                        242,
                        243,
                        246,
                        247,
                        248,
                        249,
                        250,
                        253,
                        254,
                        255,
                        256,
                        257
                    ],
                    "('parquet.hadoop.metadata#LongColumnChunkMetaData', 'getFirstDataPageOffset')": [
                        230,
                        231
                    ],
                    "('parquet.hadoop.metadata#LongColumnChunkMetaData', 'getDictionaryPageOffset')": [
                        237,
                        238
                    ],
                    "('parquet.hadoop.metadata#LongColumnChunkMetaData', 'getValueCount')": [
                        244,
                        245
                    ],
                    "('parquet.hadoop.metadata#LongColumnChunkMetaData', 'getTotalUncompressedSize')": [
                        251,
                        252
                    ],
                    "('parquet.hadoop.metadata#LongColumnChunkMetaData', 'getTotalSize')": [
                        258,
                        259
                    ]
                }
            },
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": {
                "old": {
                    "('parquet.hadoop#TestInputFormat', 'newBlock(long)')": [
                        72,
                        73,
                        74
                    ]
                },
                "new": {
                    "(None, None)": [
                        24,
                        36
                    ],
                    "('parquet.hadoop#TestInputFormat', 'newBlock(long)')": [
                        74,
                        75,
                        76
                    ]
                }
            },
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": {
                "old": {
                    "('parquet.pig#ParquetLoader', None)": [
                        94,
                        187,
                        201
                    ],
                    "('parquet.pig#ParquetLoader', 'getParquetInputFormat')": [
                        123
                    ],
                    "('parquet.pig#ParquetLoader', 'getSchemaFromRequiredFieldList(Schema,List)')": [
                        202
                    ],
                    "(None, None)": [
                        226
                    ]
                },
                "new": {
                    "(None, None)": [
                        22,
                        24,
                        27,
                        30,
                        249
                    ],
                    "('parquet.pig#ParquetLoader', None)": [
                        64,
                        65,
                        69,
                        101,
                        210,
                        224
                    ],
                    "('parquet.pig#ParquetLoader', 'setInput(String,Job)')": [
                        112
                    ],
                    "('parquet.pig#ParquetLoader', 'getParquetInputFormat')": [
                        131,
                        132,
                        133,
                        134,
                        135,
                        136,
                        137,
                        138,
                        139,
                        140,
                        141,
                        142,
                        143,
                        144,
                        145,
                        146
                    ],
                    "('parquet.pig#ParquetLoader', 'getSchemaFromRequiredFieldList(Schema,List)')": [
                        225
                    ]
                }
            }
        }
    },
    "3f19ce3df0f46399ae8c6fead520dd27049ca3d6": {
        "authored_data": "2013 Jul 12 23:41",
        "commit.message": "reduce size of splits\n",
        "commit.author.name": "julien",
        "pcid": "02d5ed256de093ccd8a6c3705dfae6cff9ae22c6",
        "changes": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": {
                "old": {
                    "('parquet.hadoop#ParquetInputFormat', 'generateSplits(List,BlockLocation,FileStatus,FileMetaData,Class,String,Map)')": [
                        205,
                        206,
                        207,
                        208,
                        209,
                        210,
                        211,
                        212,
                        213,
                        214,
                        215
                    ]
                },
                "new": {
                    "('parquet.hadoop#ParquetInputFormat', 'generateSplits(List,BlockLocation,FileStatus,FileMetaData,Class,String,Map)')": [
                        157,
                        206,
                        207,
                        208,
                        209,
                        210,
                        211,
                        212,
                        213,
                        214,
                        215
                    ]
                }
            },
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": {
                "old": {
                    "(None, None)": [
                        18,
                        19,
                        23,
                        24,
                        25
                    ],
                    "('parquet.hadoop#ParquetInputSplit', None)": [
                        44,
                        45,
                        52,
                        85,
                        90,
                        95,
                        144,
                        145,
                        148,
                        149,
                        150,
                        200
                    ],
                    "('parquet.hadoop#ParquetInputSplit', 'getSchema')": [
                        146,
                        147
                    ],
                    "('parquet.hadoop#ParquetInputSplit', 'readFields(DataInput)')": [
                        183,
                        184,
                        185,
                        186,
                        187,
                        188,
                        189,
                        190,
                        191,
                        192,
                        193,
                        194,
                        195,
                        196,
                        197,
                        198,
                        199
                    ],
                    "('parquet.hadoop#ParquetInputSplit', 'write(DataOutput)')": [
                        208,
                        209,
                        210,
                        211,
                        212
                    ],
                    "('parquet.hadoop#ParquetInputSplit', 'toString')": [
                        223,
                        224
                    ]
                },
                "new": {
                    "(None, None)": [
                        23,
                        25,
                        28,
                        34,
                        36,
                        37,
                        38
                    ],
                    "('parquet.hadoop#ParquetInputSplit', None)": [
                        46,
                        89,
                        212,
                        213,
                        226,
                        227,
                        239,
                        240,
                        241,
                        262,
                        263,
                        281,
                        282,
                        292,
                        293,
                        302,
                        303
                    ],
                    "('parquet.hadoop#ParquetInputSplit', 'readFields(DataInput)')": [
                        174,
                        175,
                        176,
                        177,
                        178,
                        179,
                        180,
                        181,
                        182,
                        183,
                        184,
                        185,
                        186,
                        187,
                        188,
                        189
                    ],
                    "('parquet.hadoop#ParquetInputSplit', 'write(DataOutput)')": [
                        197,
                        198,
                        199,
                        200,
                        201,
                        202,
                        203,
                        204,
                        205,
                        206,
                        207,
                        208,
                        209,
                        210,
                        211
                    ],
                    "('parquet.hadoop#ParquetInputSplit', 'readBlock(DataInput)')": [
                        214,
                        215,
                        216,
                        217,
                        218,
                        219,
                        220,
                        221,
                        222,
                        223,
                        224,
                        225
                    ],
                    "('parquet.hadoop#ParquetInputSplit', 'writeBlock(DataOutput,BlockMetaData)')": [
                        228,
                        229,
                        230,
                        231,
                        232,
                        233,
                        234,
                        235,
                        236,
                        237,
                        238
                    ],
                    "('parquet.hadoop#ParquetInputSplit', 'readColumn(DataInput)')": [
                        242,
                        243,
                        244,
                        245,
                        246,
                        247,
                        248,
                        249,
                        250,
                        251,
                        252,
                        253,
                        254,
                        255,
                        256,
                        257,
                        258,
                        259,
                        260,
                        261
                    ],
                    "('parquet.hadoop#ParquetInputSplit', 'writeColumn(DataOutput,ColumnChunkMetaData)')": [
                        264,
                        265,
                        266,
                        267,
                        268,
                        269,
                        270,
                        271,
                        272,
                        273,
                        274,
                        275,
                        276,
                        277,
                        278,
                        279,
                        280
                    ],
                    "('parquet.hadoop#ParquetInputSplit', 'readKeyValues(DataInput)')": [
                        283,
                        284,
                        285,
                        286,
                        287,
                        288,
                        289,
                        290,
                        291
                    ],
                    "('parquet.hadoop#ParquetInputSplit', 'writeKeyValues(DataOutput,Map)')": [
                        294,
                        295,
                        296,
                        297,
                        298,
                        299,
                        300,
                        301
                    ],
                    "('parquet.hadoop#ParquetInputSplit', 'toString')": [
                        314
                    ]
                }
            },
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": {
                "old": {
                    "('parquet.hadoop#ParquetReader', None)": [
                        66
                    ]
                }
            },
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": {
                "old": {
                    "('parquet.hadoop#ParquetRecordReader', 'initialize(InputSplit,Configuration)')": [
                        179
                    ]
                },
                "new": {
                    "('parquet.hadoop#ParquetRecordReader', 'initialize(InputSplit,Configuration)')": [
                        179
                    ]
                }
            },
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": {
                "old": {
                    "(None, None)": [
                        18
                    ],
                    "('parquet.hadoop.metadata#BlockMetaData', None)": [
                        29,
                        30
                    ]
                },
                "new": {
                    "('parquet.hadoop.metadata#BlockMetaData', None)": [
                        28
                    ]
                }
            },
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": {
                "old": {
                    "(None, None)": [
                        18
                    ],
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', None)": [
                        31,
                        32
                    ]
                },
                "new": {
                    "('parquet.hadoop.metadata#ColumnChunkMetaData', None)": [
                        30
                    ]
                }
            }
        }
    },
    "aa0bc1396bdbbc736f062be9a07675c021380b5b": {
        "authored_data": "2013 Jul 17 18:18",
        "commit.message": "Add Avro specific support to AvroParquet{Input,Output}Format\n\nThis commit generalizes AvroIndexedRecordConverter, AvroReadSupport and\nAvroRecordMaterializer to enable Parquet to read/write Avro specific\nobjects.\n",
        "commit.author.name": "Matt Massie",
        "pcid": "02d5ed256de093ccd8a6c3705dfae6cff9ae22c6",
        "changes": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": {
                "old": {
                    "('parquet.avro#AvroIndexedRecordConverter', None)": [
                        36,
                        39
                    ],
                    "('parquet.avro#AvroIndexedRecordConverter', 'start')": [
                        122,
                        123,
                        124
                    ],
                    "('parquet.avro#AvroIndexedRecordConverter', 'getCurrentRecord')": [
                        134
                    ]
                },
                "new": {
                    "('parquet.avro#AvroIndexedRecordConverter', None)": [
                        36,
                        39
                    ],
                    "('parquet.avro#AvroIndexedRecordConverter', 'start')": [
                        122,
                        123,
                        124
                    ],
                    "('parquet.avro#AvroIndexedRecordConverter', 'getCurrentRecord')": [
                        134
                    ]
                }
            },
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": {
                "old": {
                    "('parquet.avro#AvroReadSupport', None)": [
                        31
                    ],
                    "('parquet.avro#AvroReadSupport', 'prepareForRead(Configuration,Map,MessageType,ReadContext)')": [
                        39,
                        41
                    ]
                },
                "new": {
                    "('parquet.avro#AvroReadSupport', None)": [
                        31
                    ],
                    "('parquet.avro#AvroReadSupport', 'prepareForRead(Configuration,Map,MessageType,ReadContext)')": [
                        39,
                        41
                    ]
                }
            },
            "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": {
                "old": {
                    "('parquet.avro#AvroRecordMaterializer', None)": [
                        24,
                        26,
                        29
                    ],
                    "('parquet.avro#AvroRecordMaterializer', 'getCurrentRecord')": [
                        33
                    ]
                },
                "new": {
                    "('parquet.avro#AvroRecordMaterializer', None)": [
                        24,
                        26,
                        29
                    ],
                    "('parquet.avro#AvroRecordMaterializer', 'getCurrentRecord')": [
                        33
                    ]
                }
            }
        }
    },
    "02d5ed256de093ccd8a6c3705dfae6cff9ae22c6": {
        "authored_data": "2013 Jul 17 18:24",
        "commit.message": "fix merge conflict\n",
        "commit.author.name": "julien",
        "pcid": "9f41d31a313359c6b72b5094cb717d243edd6d00",
        "changes": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": {
                "old": {
                    "('parquet.hadoop#ParquetInputFormat', None)": [
                        136,
                        137,
                        141,
                        142,
                        143,
                        144,
                        145,
                        146,
                        147,
                        148,
                        149,
                        166,
                        167,
                        176,
                        177,
                        178,
                        302,
                        304,
                        341,
                        345,
                        346,
                        347,
                        348
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'listStatus(JobContext)')": [
                        138,
                        139,
                        140,
                        308,
                        309,
                        310
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'getAllFileRecursively(List,Configuration)')": [
                        150,
                        151,
                        152,
                        153,
                        154,
                        155,
                        156,
                        157,
                        158,
                        159,
                        160,
                        161,
                        162,
                        163,
                        164,
                        165,
                        327
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'addInputPathRecursively(List,FileSystem,Path,PathFilter)')": [
                        168,
                        169,
                        170,
                        171,
                        172,
                        173,
                        174,
                        175,
                        332
                    ]
                },
                "new": {
                    "('parquet.hadoop#ParquetInputFormat', None)": [
                        259,
                        261,
                        298,
                        302,
                        303,
                        304,
                        305
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'listStatus(JobContext)')": [
                        265,
                        266,
                        267
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'getAllFileRecursively(List,Configuration)')": [
                        284
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'addInputPathRecursively(List,FileSystem,Path,PathFilter)')": [
                        289
                    ]
                }
            }
        }
    }
}