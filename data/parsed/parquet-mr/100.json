{
    "862bac97bf62eb68e2ab3d2911d3b5f95fb6979e": {
        "authored_data": "2021 Feb 26 16:16",
        "commit.message": "PARQUET-1975: Do not include brotli-codec for ARM64 (#872)\n\n",
        "commit.author.name": "Martin Grigorov",
        "pcid": "548215e0c574643faca2a945cd0328b7b527466a",
        "changes": {
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java": {
                "old": {
                    "('org.apache.parquet.hadoop#TestDirectCodecFactory', None)": [
                        42
                    ],
                    "('org.apache.parquet.hadoop#TestDirectCodecFactory', 'compressionCodecs')": [
                        153
                    ]
                },
                "new": {
                    "('org.apache.parquet.hadoop#TestDirectCodecFactory', None)": [
                        42
                    ],
                    "('org.apache.parquet.hadoop#TestDirectCodecFactory', 'compressionCodecs')": [
                        153,
                        160,
                        161,
                        162,
                        163,
                        164
                    ]
                }
            }
        }
    },
    "286b078c0a205e1064e61c2efd5598795d2d8bc9": {
        "authored_data": "2021 Feb 25 09:56",
        "commit.message": "PARQUET-1977: Invalid data_page_offset (#868)\n\n",
        "commit.author.name": "Gabor Szadovszky",
        "pcid": "434667566e140d7ca7e30b568156c43a06cc719f",
        "changes": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": {
                "old": {
                    "('org.apache.parquet.hadoop#ParquetFileWriter', None)": [
                        158,
                        165
                    ],
                    "('org.apache.parquet.hadoop#ParquetFileWriter', 'startColumn(ColumnDescriptor,long,CompressionCodecName)')": [
                        440,
                        448
                    ],
                    "('org.apache.parquet.hadoop#ParquetFileWriter', 'innerWriteDataPage(int,int,BytesInput,Statistics,Encoding,Encoding,Encoding)')": [
                        603,
                        604
                    ],
                    "('org.apache.parquet.hadoop#ParquetFileWriter', 'writeDataPageV2(int,int,int,BytesInput,BytesInput,Encoding,BytesInput,int,Statistics)')": [
                        692,
                        693
                    ],
                    "('org.apache.parquet.hadoop#ParquetFileWriter', 'writeColumnChunk(ColumnDescriptor,long,CompressionCodecName,DictionaryPage,BytesInput,long,long,Statistics,ColumnIndexBuilder,OffsetIndexBuilder,BloomFilter,Set,Set,List,BlockCipher,int,int,byte)')": [
                        809
                    ],
                    "('org.apache.parquet.hadoop#ParquetFileWriter', 'endColumn')": [
                        838
                    ],
                    "('org.apache.parquet.hadoop#ParquetFileWriter', 'appendRowGroup(SeekableInputStream,BlockMetaData,boolean)')": [
                        1004,
                        1005
                    ],
                    "('org.apache.parquet.hadoop#ParquetFileWriter', 'appendColumnChunk(ColumnDescriptor,SeekableInputStream,ColumnChunkMetaData,BloomFilter,ColumnIndex,OffsetIndex)')": [
                        1046,
                        1047
                    ]
                },
                "new": {
                    "('org.apache.parquet.hadoop#ParquetFileWriter', None)": [
                        164,
                        539
                    ],
                    "('org.apache.parquet.hadoop#ParquetFileWriter', 'startColumn(ColumnDescriptor,long,CompressionCodecName)')": [
                        439
                    ],
                    "('org.apache.parquet.hadoop#ParquetFileWriter', 'writeDataPage(int,int,BytesInput,Encoding,Encoding,Encoding)')": [
                        537,
                        538
                    ],
                    "('org.apache.parquet.hadoop#ParquetFileWriter', 'innerWriteDataPage(int,int,BytesInput,Statistics,Encoding,Encoding,Encoding)')": [
                        604,
                        605
                    ],
                    "('org.apache.parquet.hadoop#ParquetFileWriter', 'writeDataPageV2(int,int,int,BytesInput,BytesInput,Encoding,BytesInput,int,Statistics)')": [
                        693,
                        694
                    ],
                    "('org.apache.parquet.hadoop#ParquetFileWriter', 'writeColumnChunk(ColumnDescriptor,long,CompressionCodecName,DictionaryPage,BytesInput,long,long,Statistics,ColumnIndexBuilder,OffsetIndexBuilder,BloomFilter,Set,Set,List,BlockCipher,int,int,byte)')": [
                        810
                    ],
                    "('org.apache.parquet.hadoop#ParquetFileWriter', 'endColumn')": [
                        839
                    ],
                    "('org.apache.parquet.hadoop#ParquetFileWriter', 'appendRowGroup(SeekableInputStream,BlockMetaData,boolean)')": [
                        998,
                        1006,
                        1007
                    ],
                    "('org.apache.parquet.hadoop#ParquetFileWriter', 'appendColumnChunk(ColumnDescriptor,SeekableInputStream,ColumnChunkMetaData,BloomFilter,ColumnIndex,OffsetIndex)')": [
                        1041,
                        1049,
                        1050
                    ]
                }
            },
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": {
                "old": {
                    "('org.apache.parquet.hadoop.metadata#ColumnChunkMetaData', None)": [
                        265
                    ]
                },
                "new": {
                    "('org.apache.parquet.hadoop.metadata#ColumnChunkMetaData', None)": [
                        265,
                        266
                    ]
                }
            },
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": {
                "old": {
                    "('org.apache.parquet.hadoop#TestParquetFileWriter', 'testWriteRead')": [
                        184,
                        185,
                        186,
                        190,
                        194
                    ]
                },
                "new": {
                    "(None, None)": [
                        42,
                        73
                    ],
                    "('org.apache.parquet.hadoop#TestParquetFileWriter', 'testWriteRead')": [
                        162,
                        169,
                        170,
                        189,
                        190,
                        191,
                        192,
                        193,
                        194,
                        195,
                        196,
                        197,
                        198,
                        199,
                        200,
                        204,
                        208
                    ]
                }
            }
        }
    },
    "434667566e140d7ca7e30b568156c43a06cc719f": {
        "authored_data": "2021 Feb 24 11:12",
        "commit.message": "PARQUET-1984: Allow tests to run on windows (#870)\n\nCheck for \\r\\n lineendings instead of \\n\r\nChange file layout (backslash and slash) to check\r\nClose files / streams before deleting file",
        "commit.author.name": "fschmalzel",
        "pcid": "ab402f84e956d17ab67b63f91d01c63a92e7ae1e",
        "changes": {
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": {
                "old": {
                    "('org.apache.parquet.format.converter#TestParquetMetadataConverter', 'testMetadataToJson')": [
                        584,
                        587
                    ]
                },
                "new": {
                    "('org.apache.parquet.format.converter#TestParquetMetadataConverter', 'testMetadataToJson')": [
                        584,
                        587
                    ]
                }
            },
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedInputFormatTest.java": {
                "old": {
                    "(None, None)": [
                        1,
                        9,
                        11
                    ],
                    "('org.apache.parquet.hadoop#DeprecatedInputFormatTest', 'testCombineParquetInputFormat')": [
                        264,
                        265,
                        266,
                        267,
                        268,
                        269,
                        270,
                        271,
                        272
                    ]
                },
                "new": {
                    "(None, None)": [
                        1,
                        9,
                        11
                    ],
                    "('org.apache.parquet.hadoop#DeprecatedInputFormatTest', 'testCombineParquetInputFormat')": [
                        264,
                        265,
                        266,
                        267,
                        268,
                        269,
                        270,
                        271,
                        272,
                        273,
                        274
                    ]
                }
            },
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": {
                "old": {
                    "('org.apache.parquet.hadoop#TestInputFormat', 'testGetFootersReturnsInPredictableOrder')": [
                        394,
                        398,
                        399,
                        400,
                        401,
                        405,
                        410
                    ]
                },
                "new": {
                    "(None, None)": [
                        45
                    ],
                    "('org.apache.parquet.hadoop#TestInputFormat', 'testGetFootersReturnsInPredictableOrder')": [
                        395,
                        399,
                        403,
                        408
                    ]
                }
            },
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": {
                "old": {
                    "('org.apache.parquet.statistics#TestStatistics', None)": [
                        116,
                        118,
                        119,
                        120,
                        121,
                        470,
                        474,
                        475,
                        476,
                        477,
                        478,
                        479,
                        480
                    ]
                },
                "new": {
                    "('org.apache.parquet.statistics#TestStatistics', None)": [
                        116,
                        118,
                        119,
                        120,
                        469,
                        473,
                        474,
                        475,
                        476,
                        477,
                        478,
                        479,
                        480
                    ]
                }
            },
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": {
                "old": {
                    "(None, None)": [
                        1,
                        9,
                        11,
                        382
                    ],
                    "('org.apache.parquet.hadoop.thrift#TestParquetToThriftReadWriteAndProjection', 'shouldDoProjection(Configuration,T,T,Class)')": [
                        374,
                        375,
                        376,
                        377,
                        378
                    ]
                },
                "new": {
                    "(None, None)": [
                        1,
                        9,
                        11
                    ],
                    "('org.apache.parquet.hadoop.thrift#TestParquetToThriftReadWriteAndProjection', 'shouldDoProjection(Configuration,T,T,Class)')": [
                        374,
                        375,
                        376,
                        377,
                        378,
                        379
                    ]
                }
            },
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftMetaData.java": {
                "old": {
                    "(None, None)": [
                        1,
                        9,
                        11
                    ],
                    "('org.apache.parquet.thrift#TestThriftMetaData', 'testToStringDoesNotThrow')": [
                        45,
                        50
                    ]
                },
                "new": {
                    "(None, None)": [
                        1,
                        9,
                        11
                    ],
                    "('org.apache.parquet.thrift#TestThriftMetaData', 'testToStringDoesNotThrow')": [
                        45,
                        50
                    ]
                }
            },
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java": {
                "old": {
                    "(None, None)": [
                        1,
                        9,
                        11
                    ],
                    "('org.apache.parquet.thrift#TestThriftRecordConverter', 'testUnknownEnumThrowsGoodException')": [
                        63,
                        75
                    ]
                },
                "new": {
                    "(None, None)": [
                        1,
                        9,
                        11
                    ],
                    "('org.apache.parquet.thrift#TestThriftRecordConverter', 'testUnknownEnumThrowsGoodException')": [
                        63,
                        75
                    ]
                }
            },
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/TestThriftType.java": {
                "old": {
                    "('org.apache.parquet.thrift.struct#TestThriftType', 'testWriteUnionInfo')": [
                        35,
                        40,
                        43,
                        48,
                        51,
                        56
                    ]
                },
                "new": {
                    "('org.apache.parquet.thrift.struct#TestThriftType', 'testWriteUnionInfo')": [
                        35,
                        40,
                        43,
                        48,
                        51,
                        56
                    ]
                }
            }
        }
    }
}