{
    "20a4bf72e9e64e317c9167eea88303b4f4e16f31": {
        "authored_data": "2013 Apr 29 04:20",
        "commit.message": "DeprecatedParquetInputFormat is not abstract\n",
        "commit.author.name": "Avi Bryant",
        "pcid": "5e82439eb8f99d20a5bbc55fdeaa0840b0cac90f",
        "changes": {
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": {
                "old": {
                    "('parquet.hadoop.mapred#DeprecatedParquetInputFormat', None)": [
                        40
                    ]
                },
                "new": {
                    "('parquet.hadoop.mapred#DeprecatedParquetInputFormat', None)": [
                        40
                    ]
                }
            }
        }
    },
    "5e82439eb8f99d20a5bbc55fdeaa0840b0cac90f": {
        "authored_data": "2013 Apr 28 23:20",
        "commit.message": "fix up cascading and scrooge to use DeprecatedParquetInputFormat\n",
        "commit.author.name": "Avi Bryant",
        "pcid": "1f0a8a25ad7d3b2683f0f8b10449db3ff1c2de13",
        "changes": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": {
                "old": {
                    "(None, None)": [
                        25,
                        26
                    ],
                    "('parquet.cascading#ParquetTBaseScheme', 'sourceConfInit(FlowProcess,Tap,JobConf)')": [
                        55,
                        56
                    ],
                    "('parquet.cascading#ParquetTBaseScheme', None)": [
                        58
                    ]
                },
                "new": {
                    "(None, None)": [
                        25,
                        26
                    ],
                    "('parquet.cascading#ParquetTBaseScheme', 'sourceConfInit(FlowProcess,Tap,JobConf)')": [
                        55,
                        56
                    ]
                }
            },
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": {
                "old": {
                    "(None, None)": [
                        24
                    ]
                },
                "new": {
                    "(None, None)": [
                        24
                    ]
                }
            },
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": {
                "old": {
                    "(None, None)": [
                        26
                    ],
                    "('parquet.scrooge#ParquetScroogeScheme', 'sourceConfInit(FlowProcess,Tap,JobConf)')": [
                        62,
                        63
                    ],
                    "('parquet.scrooge#ParquetScroogeScheme', None)": [
                        66
                    ]
                },
                "new": {
                    "(None, None)": [
                        26,
                        27
                    ],
                    "('parquet.scrooge#ParquetScroogeScheme', 'sourceConfInit(FlowProcess,Tap,JobConf)')": [
                        63,
                        64
                    ]
                }
            }
        }
    },
    "1f0a8a25ad7d3b2683f0f8b10449db3ff1c2de13": {
        "authored_data": "2013 Apr 28 23:05",
        "commit.message": "replace DeprecatedContainerInputFormat with DeprecatedParquetInputFormat, should build under MR2\n",
        "commit.author.name": "Avi Bryant",
        "pcid": "a5d72a44117e7263c0e39be8ffcf5992f4e45b89",
        "changes": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": {
                "old": {
                    "('parquet.hadoop#ParquetInputFormat', 'getReadSupport(Configuration)')": [
                        118
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'generateSplits(List,BlockLocation,FileStatus,FileMetaData,Class,String)')": [
                        154,
                        187
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'getSplits(JobContext)')": [
                        215,
                        216,
                        217
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'getFooters(JobContext)')": [
                        250,
                        251,
                        253,
                        254,
                        255
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'getGlobalMetaData(JobContext)')": [
                        265
                    ],
                    "(None, None)": [
                        271
                    ]
                },
                "new": {
                    "('parquet.hadoop#ParquetInputFormat', 'getReadSupport(Configuration)')": [
                        118
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'generateSplits(List,BlockLocation,FileStatus,FileMetaData,Class,String)')": [
                        154,
                        187
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'getSplits(JobContext)')": [
                        215,
                        216
                    ],
                    "('parquet.hadoop#ParquetInputFormat', None)": [
                        217,
                        218,
                        258,
                        259,
                        272,
                        273
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'getSplits(Configuration,List)')": [
                        219,
                        220,
                        221
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'getFooters(JobContext)')": [
                        254,
                        255,
                        256,
                        257
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'getFooters(Configuration,List)')": [
                        260,
                        262
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'getGlobalMetaData(JobContext)')": [
                        271
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'getGlobalMetaData(List)')": [
                        274,
                        276
                    ]
                }
            },
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": {
                "old": {
                    "('parquet.hadoop#ParquetRecordReader', 'initialize(InputSplit,TaskAttemptContext)')": [
                        151,
                        153
                    ]
                },
                "new": {
                    "('parquet.hadoop#ParquetRecordReader', 'initialize(InputSplit,TaskAttemptContext)')": [
                        151,
                        153
                    ],
                    "('parquet.hadoop#ParquetRecordReader', None)": [
                        154,
                        155
                    ],
                    "('parquet.hadoop#ParquetRecordReader', 'initialize(InputSplit,Configuration)')": [
                        156,
                        157
                    ]
                }
            },
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": {
                "old": {
                    "('parquet.hadoop#TestInputFormat', 'testBlocksToSplits')": [
                        55,
                        58
                    ]
                },
                "new": {
                    "('parquet.hadoop#TestInputFormat', 'testBlocksToSplits')": [
                        55,
                        58
                    ]
                }
            }
        }
    },
    "593a105cea2faa01849240e140a6f9fd03bd31f7": {
        "authored_data": "2013 Apr 28 05:14",
        "commit.message": "short class comment for the TupleScheme\n",
        "commit.author.name": "Avi Bryant",
        "pcid": "065a3c90673a7b3eae9165db0c4f0786372153dd",
        "changes": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": {
                "new": {
                    "(None, None)": [
                        27,
                        28,
                        29,
                        30,
                        31,
                        32,
                        33,
                        34,
                        35,
                        36,
                        37
                    ],
                    "('parquet.cascading#ParquetTupleScheme', None)": [
                        42,
                        43,
                        44,
                        45
                    ]
                }
            }
        }
    },
    "065a3c90673a7b3eae9165db0c4f0786372153dd": {
        "authored_data": "2013 Apr 28 05:06",
        "commit.message": "working selective tuple materialization for cascading\n",
        "commit.author.name": "Avi Bryant",
        "pcid": "6b867e502c1b9cfe6b10e1e7387d93ef2969e7e4",
        "changes": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": {
                "old": {
                    "('parquet.cascading#ParquetTupleScheme', 'retrieveSourceFields(FlowProcess,Tap)')": [
                        47,
                        48,
                        49,
                        50,
                        51,
                        52
                    ],
                    "('parquet.cascading#ParquetTupleScheme', 'readSchema(FlowProcess,Path)')": [
                        57,
                        58,
                        59
                    ]
                },
                "new": {
                    "(None, None)": [
                        23
                    ],
                    "('parquet.cascading#ParquetTupleScheme', 'retrieveSourceFields(FlowProcess,Tap)')": [
                        47,
                        48,
                        50
                    ],
                    "('parquet.cascading#ParquetTupleScheme', 'readSchema(FlowProcess,Tap)')": [
                        55,
                        56,
                        57,
                        58,
                        59,
                        60,
                        61,
                        62,
                        63,
                        64,
                        65,
                        66,
                        67
                    ],
                    "('parquet.cascading#ParquetTupleScheme', None)": [
                        68
                    ]
                }
            },
            "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": {
                "old": {
                    "('parquet.cascading#TupleReadSupport', 'getRequestedFields(Configuration)')": [
                        19,
                        20
                    ],
                    "('parquet.cascading#TupleReadSupport', 'setRequestedFields(Configuration,Fields)')": [
                        23,
                        24,
                        25
                    ],
                    "('parquet.cascading#TupleReadSupport', None)": [
                        26,
                        27,
                        31,
                        32
                    ],
                    "('parquet.cascading#TupleReadSupport', 'parseFieldsString(String)')": [
                        28,
                        29,
                        30
                    ],
                    "('parquet.cascading#TupleReadSupport', 'buildFieldsString(Fields)')": [
                        33,
                        34,
                        35
                    ],
                    "('parquet.cascading#TupleReadSupport', 'init(Configuration,Map,MessageType)')": [
                        44
                    ]
                },
                "new": {
                    "(None, None)": [
                        4,
                        7,
                        11,
                        18
                    ],
                    "('parquet.cascading#TupleReadSupport', 'getRequestedFields(Configuration)')": [
                        23,
                        24,
                        25,
                        26,
                        27
                    ],
                    "('parquet.cascading#TupleReadSupport', None)": [
                        28,
                        38
                    ],
                    "('parquet.cascading#TupleReadSupport', 'setRequestedFields(JobConf,Fields)')": [
                        31,
                        32,
                        33,
                        34,
                        35,
                        36,
                        37
                    ],
                    "('parquet.cascading#TupleReadSupport', 'init(Configuration,Map,MessageType)')": [
                        47,
                        48
                    ]
                }
            },
            "parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java": {
                "old": {
                    "('parquet.cascading.convert#TupleConverter', 'start')": [
                        47
                    ]
                },
                "new": {
                    "('parquet.cascading.convert#TupleConverter', 'start')": [
                        47
                    ]
                }
            },
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": {
                "new": {
                    "('parquet.hadoop#ParquetFileReader', None)": [
                        229,
                        240,
                        241,
                        242
                    ],
                    "('parquet.hadoop#ParquetFileReader', 'readAnyFooter(Configuration,Path)')": [
                        230,
                        231,
                        232,
                        233,
                        234,
                        235,
                        236,
                        237,
                        238,
                        239
                    ]
                }
            }
        }
    },
    "5db276f1a6b5132b9c19936bc17f9aa73c36012e": {
        "authored_data": "2013 Apr 26 21:43",
        "commit.message": "cleanup import\n",
        "commit.author.name": "julien",
        "pcid": "7c0f1a6779e49166d2925b6afebabb58cb81bb9e",
        "changes": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": {
                "old": {
                    "(None, None)": [
                        23
                    ]
                }
            }
        }
    },
    "7c0f1a6779e49166d2925b6afebabb58cb81bb9e": {
        "authored_data": "2013 Apr 26 21:41",
        "commit.message": "rename fromSequence to concat\n",
        "commit.author.name": "julien",
        "pcid": "e5484323922826f66c22e5d5d4b2dae0fe521b42",
        "changes": {
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": {
                "old": {
                    "('parquet.bytes#BytesInput', 'fromSequence(BytesInput)')": [
                        46
                    ],
                    "('parquet.bytes#BytesInput', 'fromSequence(List)')": [
                        55
                    ]
                },
                "new": {
                    "('parquet.bytes#BytesInput', 'concat(BytesInput)')": [
                        46
                    ],
                    "('parquet.bytes#BytesInput', 'concat(List)')": [
                        55
                    ]
                }
            },
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": {
                "old": {
                    "('parquet.column.impl#ColumnWriterImpl', 'writePage')": [
                        78
                    ]
                },
                "new": {
                    "(None, None)": [
                        17,
                        18
                    ],
                    "('parquet.column.impl#ColumnWriterImpl', 'writePage')": [
                        80
                    ]
                }
            },
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": {
                "old": {
                    "('parquet.column.values.bitpacking#ByteBasedBitPackingEncoder', 'toBytes')": [
                        98,
                        99,
                        100
                    ],
                    "('parquet.column.values.bitpacking#ByteBasedBitPackingEncoder', None)": [
                        101
                    ]
                },
                "new": {
                    "(None, None)": [
                        17,
                        18
                    ],
                    "('parquet.column.values.bitpacking#ByteBasedBitPackingEncoder', 'toBytes')": [
                        100
                    ]
                }
            },
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": {
                "old": {
                    "('parquet.column.values.boundedint#BoundedIntValuesWriter', 'getBytes')": [
                        85
                    ]
                },
                "new": {
                    "(None, None)": [
                        18
                    ],
                    "('parquet.column.values.boundedint#BoundedIntValuesWriter', 'getBytes')": [
                        86
                    ]
                }
            },
            "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": {
                "old": {
                    "('parquet.column.values.rle#RLESimpleEncoder', 'toBytes')": [
                        49,
                        50,
                        51
                    ],
                    "(None, None)": [
                        52
                    ]
                },
                "new": {
                    "(None, None)": [
                        17,
                        18
                    ],
                    "('parquet.column.values.rle#RLESimpleEncoder', 'toBytes')": [
                        51
                    ]
                }
            }
        }
    }
}