{
    "b55eea04135d41a67b8c5d321f993ccf35a17c99": {
        "authored_data": "2014 Apr 17 22:28",
        "commit.message": "make ParquetFileWriter throw IOException in invalid state case\n",
        "commit.author.name": "julien",
        "pcid": "41df19051825d724626e91425c8e690c04a39998",
        "changes": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": {
                "old": {
                    "('parquet.hadoop#ParquetFileWriter', None)": [
                        124,
                        125,
                        126,
                        127,
                        128,
                        129,
                        130
                    ]
                },
                "new": {
                    "('parquet.hadoop#ParquetFileWriter', None)": [
                        124,
                        125,
                        126,
                        127,
                        128,
                        129,
                        130,
                        131,
                        132,
                        133,
                        134
                    ]
                }
            }
        }
    },
    "f4a0900ba9fecfa81b2fb15eb1b562b0beff6371": {
        "authored_data": "2014 Apr 17 18:21",
        "commit.message": "remove unused code\n",
        "commit.author.name": "Tianshuo Deng",
        "pcid": "796b7dd3d6fa9ec70e36d9502c0f79bbd94550fb",
        "changes": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": {
                "old": {
                    "('parquet.hadoop.thrift#ThriftReadSupport', 'init(InitContext)')": [
                        105
                    ]
                }
            }
        }
    },
    "3321b67329a895171d47e321279901d0dc346aad": {
        "authored_data": "2014 Apr 17 18:12",
        "commit.message": "fix enum to be upper case\n",
        "commit.author.name": "Tianshuo Deng",
        "pcid": "6417baede9f9e9b4cb711d7120ee31499a19b5ea",
        "changes": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": {
                "old": {
                    "('parquet.scrooge#ScroogeStructConverter', 'convertEnumTypeField(ThriftStructField)')": [
                        278
                    ]
                },
                "new": {
                    "('parquet.scrooge#ScroogeStructConverter', 'convertEnumTypeField(ThriftStructField)')": [
                        278
                    ]
                }
            }
        }
    },
    "796b7dd3d6fa9ec70e36d9502c0f79bbd94550fb": {
        "authored_data": "2014 Apr 17 17:40",
        "commit.message": "do not call schema converter to generate projected schema when the projectionFilterStrubg or projectionSchemaStr is specified\n",
        "commit.author.name": "Tianshuo Deng",
        "pcid": "41df19051825d724626e91425c8e690c04a39998",
        "changes": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": {
                "old": {
                    "('parquet.hadoop.thrift#ThriftReadSupport', 'init(InitContext)')": [
                        95,
                        97,
                        102,
                        103
                    ]
                },
                "new": {
                    "('parquet.hadoop.thrift#ThriftReadSupport', 'init(InitContext)')": [
                        95,
                        97,
                        100,
                        103,
                        104
                    ]
                }
            }
        }
    },
    "5d06526d49451135bd5c3befc06a64624431de02": {
        "authored_data": "2014 Apr 16 19:53",
        "commit.message": "generate splits by min max size, and align to HDFS block when possible\n",
        "commit.author.name": "Tianshuo Deng",
        "pcid": "41df19051825d724626e91425c8e690c04a39998",
        "changes": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": {
                "old": {
                    "('parquet.hadoop#ParquetInputFormat', None)": [
                        158,
                        159,
                        160,
                        161,
                        162,
                        163
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'generateSplits(List,BlockLocation,FileStatus,FileMetaData,Class,String,Map)')": [
                        169,
                        170,
                        171,
                        172,
                        173,
                        174,
                        175,
                        177,
                        178,
                        179,
                        180,
                        181,
                        182,
                        183,
                        184,
                        185,
                        186,
                        187,
                        188,
                        189,
                        190,
                        191,
                        192,
                        193,
                        194,
                        195,
                        196,
                        197,
                        198,
                        199,
                        200,
                        201,
                        202,
                        203,
                        204,
                        205,
                        206,
                        207,
                        208,
                        209,
                        210,
                        211,
                        212,
                        213,
                        214,
                        215,
                        216,
                        217,
                        218,
                        219,
                        220,
                        221,
                        224,
                        225,
                        226,
                        227,
                        228,
                        229,
                        230,
                        231,
                        232,
                        233,
                        234,
                        235,
                        236,
                        237
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'getSplits(Configuration,List)')": [
                        279
                    ]
                },
                "new": {
                    "(None, None)": [
                        51
                    ],
                    "('parquet.hadoop#ParquetInputFormat', None)": [
                        157,
                        158,
                        159,
                        160,
                        161,
                        162,
                        163,
                        164,
                        165,
                        166,
                        167,
                        168,
                        169,
                        170,
                        171,
                        172,
                        173,
                        174,
                        175,
                        176,
                        177,
                        178,
                        179,
                        180,
                        181,
                        182,
                        183,
                        184,
                        185,
                        186,
                        187,
                        188,
                        189,
                        190,
                        191,
                        192,
                        193,
                        194,
                        195,
                        196,
                        197,
                        198,
                        199,
                        200,
                        201,
                        202,
                        203,
                        204,
                        205,
                        206,
                        207,
                        208,
                        209,
                        210,
                        211,
                        212,
                        213,
                        214,
                        215,
                        216,
                        217,
                        218,
                        219,
                        220,
                        221,
                        222,
                        223,
                        224,
                        225,
                        226,
                        227,
                        228,
                        229,
                        230,
                        231,
                        232,
                        233,
                        234,
                        235,
                        236,
                        239,
                        240,
                        241,
                        242,
                        243,
                        244,
                        245,
                        247,
                        248
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'generateSplits(List,BlockLocation,FileStatus,FileMetaData,Class,String,Map,long,long)')": [
                        253,
                        254,
                        255,
                        256,
                        257,
                        258,
                        259,
                        261,
                        262,
                        263,
                        264,
                        265,
                        266,
                        267,
                        268,
                        269,
                        270,
                        271,
                        272,
                        273,
                        274,
                        275,
                        276,
                        277,
                        278,
                        279,
                        280,
                        281,
                        282,
                        283,
                        284,
                        285,
                        286,
                        287,
                        288,
                        289,
                        290,
                        291,
                        292,
                        293,
                        294,
                        297,
                        298,
                        299,
                        300,
                        301,
                        302,
                        303,
                        304,
                        305,
                        306,
                        307,
                        308,
                        309,
                        310,
                        311
                    ],
                    "('parquet.hadoop#ParquetInputFormat', 'getSplits(Configuration,List)')": [
                        331,
                        332,
                        355,
                        356,
                        357
                    ]
                }
            },
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": {
                "old": {
                    "(None, None)": [
                        18,
                        19,
                        20,
                        21,
                        22,
                        23,
                        24,
                        25,
                        26
                    ],
                    "('parquet.hadoop#TestInputFormat', 'testBlocksToSplits')": [
                        46,
                        47,
                        48,
                        49,
                        50,
                        51,
                        52,
                        53,
                        54,
                        55,
                        56,
                        57,
                        58,
                        59,
                        60,
                        61,
                        62,
                        63,
                        64,
                        65,
                        66,
                        67,
                        68
                    ],
                    "('parquet.hadoop#TestInputFormat', 'newBlock(long)')": [
                        72,
                        75,
                        76
                    ]
                },
                "new": {
                    "(None, None)": [
                        21,
                        35,
                        36,
                        37,
                        38,
                        39
                    ],
                    "('parquet.hadoop#TestInputFormat', None)": [
                        42,
                        43,
                        44,
                        45,
                        46,
                        47,
                        48,
                        49,
                        50,
                        51,
                        52,
                        53,
                        54,
                        68,
                        69,
                        70,
                        71,
                        72,
                        84,
                        85,
                        86,
                        87,
                        88,
                        89,
                        90,
                        96,
                        97,
                        98,
                        99,
                        100,
                        101,
                        102,
                        103,
                        109,
                        110,
                        111,
                        112,
                        113,
                        114,
                        115,
                        121,
                        122,
                        123,
                        124,
                        125,
                        126,
                        127,
                        133,
                        134,
                        140,
                        141,
                        142,
                        155,
                        156,
                        157,
                        162,
                        163,
                        164
                    ],
                    "('parquet.hadoop#TestInputFormat', 'setUp')": [
                        55,
                        56,
                        57,
                        58,
                        59,
                        60,
                        61,
                        62,
                        63,
                        64,
                        65,
                        66,
                        67
                    ],
                    "('parquet.hadoop#TestInputFormat', 'testGenerateSplitsAlignedWithHDFSBlock')": [
                        74,
                        75,
                        76,
                        77,
                        78,
                        79,
                        80,
                        81,
                        82,
                        83
                    ],
                    "('parquet.hadoop#TestInputFormat', 'testGenerateSplitsNotAlignedWithHDFSBlock')": [
                        91,
                        92,
                        93,
                        94,
                        95
                    ],
                    "('parquet.hadoop#TestInputFormat', 'testGenerateSplitsSmallerThanMaxSizeAndAlignToHDFS')": [
                        104,
                        105,
                        106,
                        107,
                        108
                    ],
                    "('parquet.hadoop#TestInputFormat', 'testGenerateSplitsCrossHDFSBlockBoundaryToSatisfyMinSize')": [
                        116,
                        117,
                        118,
                        119,
                        120
                    ],
                    "('parquet.hadoop#TestInputFormat', 'testMultipleRowGroupsInABlockToAlignHDFSBlock')": [
                        128,
                        129,
                        130,
                        131,
                        132
                    ],
                    "('parquet.hadoop#TestInputFormat', 'generateSplitByMinMaxSize(long,long)')": [
                        135,
                        136,
                        137,
                        138,
                        139
                    ],
                    "('parquet.hadoop#TestInputFormat', 'shouldSplitBlockSizeBe(List,int)')": [
                        143,
                        144,
                        145,
                        146,
                        147
                    ],
                    "('parquet.hadoop#TestInputFormat', 'shouldSplitLocationBe(List,int)')": [
                        151,
                        152,
                        153,
                        154
                    ],
                    "('parquet.hadoop#TestInputFormat', 'shouldSplitLengthBe(List,int)')": [
                        158,
                        159,
                        160,
                        161
                    ],
                    "('parquet.hadoop#TestInputFormat', 'newBlock(long,long)')": [
                        165,
                        168,
                        169,
                        171
                    ]
                }
            }
        }
    },
    "3fad81609562f2819639f4fdb02d6d6481a7165b": {
        "authored_data": "2014 Apr 15 23:00",
        "commit.message": "Fix output bug during parquet-dump command\n\nIt was outputting the current definition level as both the repetition &\ndefinition level for the current value.\n",
        "commit.author.name": "Neal Sidhwaney",
        "pcid": "41df19051825d724626e91425c8e690c04a39998",
        "changes": {
            "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": {
                "old": {
                    "('parquet.tools.command#DumpCommand', 'dump(PrettyPrintWriter,ColumnReadStoreImpl,ColumnDescriptor,long,long,long)')": [
                        266
                    ]
                },
                "new": {
                    "('parquet.tools.command#DumpCommand', 'dump(PrettyPrintWriter,ColumnReadStoreImpl,ColumnDescriptor,long,long,long)')": [
                        266
                    ]
                }
            }
        }
    },
    "d093f497007e140c9ee0350b88d5b93b00ab9382": {
        "authored_data": "2014 Apr 15 22:41",
        "commit.message": "reverse codec changes\n",
        "commit.author.name": "julien",
        "pcid": "110fe216e493ebe52eea32275a7fc0896552ab3c",
        "changes": {
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": {
                "old": {
                    "(None, None)": [
                        39,
                        40,
                        41
                    ]
                }
            },
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": {
                "old": {
                    "('parquet.hadoop.codec#CodecConfigTest', 'testReadingCodecs')": [
                        38,
                        39
                    ]
                },
                "new": {
                    "('parquet.hadoop.codec#CodecConfigTest', 'testReadingCodecs')": [
                        38,
                        39
                    ]
                }
            }
        }
    },
    "110fe216e493ebe52eea32275a7fc0896552ab3c": {
        "authored_data": "2014 Apr 15 21:40",
        "commit.message": "fix test runtime dep missing from pig\n",
        "commit.author.name": "julien",
        "pcid": "f8877f1648b607a288af159c810b32049a49e086",
        "changes": {
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": {
                "old": {
                    "('parquet.hadoop.codec#CodecConfigTest', 'testReadingCodecs')": [
                        38,
                        39
                    ]
                },
                "new": {
                    "('parquet.hadoop.codec#CodecConfigTest', 'testReadingCodecs')": [
                        38,
                        39
                    ]
                }
            }
        }
    },
    "f8877f1648b607a288af159c810b32049a49e086": {
        "authored_data": "2014 Apr 15 01:32",
        "commit.message": "cleanup log messages for default codec\n",
        "commit.author.name": "julien",
        "pcid": "9ef1be6697ed432e5de5d5d7aa2f5810e134350a",
        "changes": {
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": {
                "new": {
                    "(None, None)": [
                        39,
                        40,
                        41
                    ]
                }
            }
        }
    }
}