{
    "4288aa65dc642c23dd90110209653c4033f9dbe1": {
        "authored_data": "2013 Aug 15 22:58",
        "commit.message": "formatting\n",
        "commit.author.name": "Tianshuo Deng",
        "pcid": "c2697261fdd7ebc10badaf89563ec4c2ed0c4804",
        "changes": {
            "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": {
                "old": {
                    "('parquet.hadoop.example#GroupReadSupportTest', 'testInitWithPartialSchema')": [
                        42
                    ]
                },
                "new": {
                    "('parquet.hadoop.example#GroupReadSupportTest', 'testInitWithoutSpecifyingRequestSchema')": [
                        30
                    ],
                    "('parquet.hadoop.example#GroupReadSupportTest', 'testInitWithPartialSchema')": [
                        42
                    ]
                }
            }
        }
    },
    "c2697261fdd7ebc10badaf89563ec4c2ed0c4804": {
        "authored_data": "2013 Aug 15 22:57",
        "commit.message": "formatting\n",
        "commit.author.name": "Tianshuo Deng",
        "pcid": "9394c097b9c19070fffd8143dcdcb4c60765be2d",
        "changes": {
            "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": {
                "old": {
                    "(None, None)": [
                        8,
                        11
                    ]
                }
            }
        }
    },
    "9394c097b9c19070fffd8143dcdcb4c60765be2d": {
        "authored_data": "2013 Aug 15 22:55",
        "commit.message": "fix test\n",
        "commit.author.name": "Tianshuo Deng",
        "pcid": "ea62ffe142871844b605d5300bd2a07dff785f17",
        "changes": {
            "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": {
                "old": {
                    "('parquet.hadoop.example#GroupReadSupportTest', None)": [
                        14,
                        19,
                        21
                    ],
                    "('parquet.hadoop.example#GroupReadSupportTest', 'testInitWithoutSpecifyingRequestSchema')": [
                        27,
                        28,
                        29,
                        30,
                        31
                    ],
                    "('parquet.hadoop.example#GroupReadSupportTest', 'testInitWithPartialSchema')": [
                        36,
                        37,
                        38,
                        39,
                        40,
                        41
                    ]
                },
                "new": {
                    "(None, None)": [
                        8,
                        11
                    ],
                    "('parquet.hadoop.example#GroupReadSupportTest', None)": [
                        16,
                        21
                    ],
                    "('parquet.hadoop.example#GroupReadSupportTest', 'testInitWithoutSpecifyingRequestSchema')": [
                        28,
                        29,
                        30,
                        31,
                        32
                    ],
                    "('parquet.hadoop.example#GroupReadSupportTest', 'testInitWithPartialSchema')": [
                        37,
                        38,
                        39,
                        40,
                        41,
                        42
                    ]
                }
            }
        }
    },
    "ccf32c7ce4cd85556336fe769389f3f257668ecb": {
        "authored_data": "2013 Aug 15 21:54",
        "commit.message": "remove comments\n",
        "commit.author.name": "Tianshuo Deng",
        "pcid": "2cc9321b41806955d55358e361d454d31f4f0627",
        "changes": {
            "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": {
                "old": {
                    "('parquet.hadoop.util#BenchmarkCounter', None)": [
                        23,
                        39
                    ],
                    "('parquet.hadoop.util#BenchmarkCounter', 'initCounterFromContext(TaskInputOutputContext)')": [
                        25
                    ]
                }
            }
        }
    },
    "2cc9321b41806955d55358e361d454d31f4f0627": {
        "authored_data": "2013 Aug 15 19:13",
        "commit.message": "add test for no benchmark counters\n",
        "commit.author.name": "Tianshuo Deng",
        "pcid": "43ad5e5257e03e8fb6ad738d61bf1e4ae132b6fc",
        "changes": {
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": {
                "old": {
                    "('parquet.hadoop.example#TestInputOutputFormat', None)": [
                        50,
                        56
                    ],
                    "('parquet.hadoop.example#TestInputOutputFormat', 'runMapReduceJob(CompressionCodecName)')": [
                        90
                    ],
                    "('parquet.hadoop.example#TestInputOutputFormat', 'testReadWriteWithCounter')": [
                        157,
                        158,
                        160
                    ]
                },
                "new": {
                    "('parquet.hadoop.example#TestInputOutputFormat', None)": [
                        50,
                        56,
                        162,
                        163,
                        164
                    ],
                    "('parquet.hadoop.example#TestInputOutputFormat', 'setUp')": [
                        59
                    ],
                    "('parquet.hadoop.example#TestInputOutputFormat', 'runMapReduceJob(CompressionCodecName)')": [
                        91
                    ],
                    "('parquet.hadoop.example#TestInputOutputFormat', 'testReadWriteWithCounter')": [
                        158,
                        159,
                        161
                    ],
                    "('parquet.hadoop.example#TestInputOutputFormat', 'testReadWriteWithoutCounter')": [
                        165,
                        166,
                        167,
                        168,
                        169,
                        170,
                        171,
                        172
                    ]
                }
            }
        }
    },
    "43ad5e5257e03e8fb6ad738d61bf1e4ae132b6fc": {
        "authored_data": "2013 Aug 15 19:04",
        "commit.message": "fix test\n",
        "commit.author.name": "Tianshuo Deng",
        "pcid": "a274684f2257aecb27404130a938758cd36504e9",
        "changes": {
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": {
                "old": {
                    "('parquet.hadoop.example#TestInputOutputFormat', None)": [
                        50
                    ]
                },
                "new": {
                    "('parquet.hadoop.example#TestInputOutputFormat', None)": [
                        50
                    ]
                }
            }
        }
    },
    "a274684f2257aecb27404130a938758cd36504e9": {
        "authored_data": "2013 Aug 15 19:03",
        "commit.message": "added 3 counters to parquet for benchmarking bytes read and time spent\n",
        "commit.author.name": "Tianshuo Deng",
        "pcid": "6ff02643a66b1e25ac3edca94433ac7c7e781f7d",
        "changes": {
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": {
                "new": {
                    "(None, None)": [
                        29
                    ],
                    "('parquet.hadoop#InternalParquetRecordReader', 'checkRead')": [
                        104
                    ]
                }
            },
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": {
                "new": {
                    "(None, None)": [
                        61
                    ],
                    "('parquet.hadoop#ParquetFileReader', 'readNextRowGroup')": [
                        316,
                        319
                    ]
                }
            },
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": {
                "new": {
                    "(None, None)": [
                        23,
                        26
                    ],
                    "('parquet.hadoop#ParquetRecordReader', 'initialize(InputSplit,TaskAttemptContext)')": [
                        97,
                        98,
                        99
                    ]
                }
            },
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": {
                "old": {
                    "('parquet.hadoop.util#ContextUtil', None)": [
                        137
                    ]
                },
                "new": {
                    "(None, None)": [
                        35,
                        255,
                        256
                    ],
                    "('parquet.hadoop.util#ContextUtil', None)": [
                        61,
                        139,
                        152,
                        239,
                        243,
                        244,
                        245,
                        246,
                        247
                    ],
                    "('parquet.hadoop.util#ContextUtil', 'getCounter(TaskInputOutputContext,String,String)')": [
                        240,
                        241,
                        242
                    ],
                    "('parquet.hadoop.util#ContextUtil', 'invoke(Method,Object,Object)')": [
                        248,
                        249,
                        250,
                        251,
                        252,
                        253,
                        254
                    ]
                }
            },
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": {
                "old": {
                    "(None, None)": [
                        19,
                        20
                    ],
                    "('parquet.hadoop.example#TestInputOutputFormat', None)": [
                        48,
                        61
                    ],
                    "('parquet.hadoop.example#TestInputOutputFormat', 'testReadWrite(CompressionCodecName)')": [
                        67,
                        69,
                        70,
                        71,
                        76,
                        77,
                        78,
                        79,
                        80,
                        81,
                        82,
                        83,
                        85,
                        86,
                        87,
                        88,
                        89,
                        90,
                        91,
                        92,
                        95,
                        96,
                        97,
                        98,
                        99,
                        100,
                        101,
                        102,
                        103
                    ]
                },
                "new": {
                    "(None, None)": [
                        19,
                        35,
                        41,
                        43
                    ],
                    "('parquet.hadoop.example#TestInputOutputFormat', None)": [
                        49,
                        50,
                        51,
                        52,
                        53,
                        54,
                        55,
                        57,
                        68,
                        69,
                        70,
                        83,
                        126,
                        145,
                        153,
                        154,
                        161,
                        162
                    ],
                    "('parquet.hadoop.example#TestInputOutputFormat', 'setUp')": [
                        58,
                        59,
                        60,
                        61,
                        62,
                        63,
                        64,
                        65,
                        66,
                        67
                    ],
                    "('parquet.hadoop.example#TestInputOutputFormat', 'runMapReduceJob(CompressionCodecName)')": [
                        89,
                        95,
                        96,
                        97,
                        98,
                        99,
                        100,
                        101,
                        102,
                        103,
                        105,
                        106,
                        107,
                        108,
                        109,
                        112,
                        113,
                        114,
                        115,
                        116,
                        117,
                        118,
                        119,
                        120,
                        121,
                        122,
                        123,
                        124
                    ],
                    "('parquet.hadoop.example#TestInputOutputFormat', 'testReadWrite(CompressionCodecName)')": [
                        128,
                        129
                    ],
                    "('parquet.hadoop.example#TestInputOutputFormat', 'testReadWriteWithCounter')": [
                        155,
                        156,
                        157,
                        158,
                        159,
                        160
                    ]
                }
            }
        }
    }
}